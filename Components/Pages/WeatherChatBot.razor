
@inject GeminiWeatherSummaryService GeminiService
@using BlazorApp.Services
@using BlazorApp.Models
@inject IJSRuntime JS

<MudCard Class="p-4">
   
    <MudPaper Class="p-2 my-2" Style="max-height: 300px; overflow-y: auto;">
        @foreach (var message in Messages)
        {
            <div class="mb-2">
                <b>@(message.Role == "user" ? "You" : "Generative AI"):</b> @message.Content
            </div>
        }
        @if (IsLoading)
        {
            <div class="mb-2 text-blue-500">
                <b>Generative AI:</b> <em>Typing...</em> @* <MudProgressCircular Indeterminate="true" Size="Size.Small" Color="Color.Primary" /> *@
            </div>
        }
    </MudPaper>

    <MudTextField @bind-Value="UserMessage" Placeholder="Ask something..." Adornment="Adornment.End" AdornmentIcon="@Icons.Material.Filled.ArrowForward" OnAdornmentClick="SendMessage" />
    <MudButton OnClick="ClearChat" Color="Color.Error" Class="mt-2">Clear Chat</MudButton>
   @*  <MudButton OnClick="StartVoiceInput" Color="Color.Primary" Class="mt-2">
        🎙️ Speak
    </MudButton> *@
</MudCard>
@code {
    private string UserMessage = "";
    private bool IsLoading = false;

    private List<GeminiChatMessage> Messages = new();
    private DotNetObjectReference<WeatherChatBot>? _dotNetRef;


    protected override void OnInitialized()
    {
        _dotNetRef = DotNetObjectReference.Create(this);
    }

    public async Task StartVoiceInput()
    {
        await JS.InvokeVoidAsync("startVoiceRecognition", _dotNetRef);
    }

    [JSInvokable]
    public async Task ReceiveVoiceInput(string transcript)
    {
        UserMessage = transcript;
        await SendMessage();
    }

    private async Task SendMessage()
    {
        if (string.IsNullOrWhiteSpace(UserMessage))
            return;

        Messages.Add(new GeminiChatMessage { Role = "user", Content = UserMessage });
        IsLoading = true;
        StateHasChanged(); // Immediately reflect loading in UI

        try
        {
            var reply = await GeminiService.GenerateChatResponseAsync(Messages);
            Messages.Add(new GeminiChatMessage { Role = "model", Content = reply });
        }
        catch (Exception ex)
        {
            Messages.Add(new GeminiChatMessage { Role = "model", Content = $"[Error: {ex.Message}]" });
        }

        UserMessage = "";
        IsLoading = false;
        StateHasChanged(); // Refresh again to hide loading
    }


    private void ClearChat()
    {
        Messages.Clear();
    }
}@* 
<script>
    window.startVoiceRecognition = function (dotNetRef) {
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'en-US';
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        recognition.onresult = function (event) {
            const transcript = event.results[0][0].transcript;
            dotNetRef.invokeMethodAsync('ReceiveVoiceInput', transcript);
        };

        recognition.onerror = function (event) {
            alert("Speech recognition error: " + event.error); // 🛠️ Show error to user
            console.error('Speech recognition error:', event.error);
        };

        recognition.start();
    };
</script> *@
